---------        ModèleV1        ---------
    private static final double LEARNING_RATE = 0.01;//0.01
    private static final double DISCOUNT_FACTOR = 0.99;//0.99
    private static double EXPLORATION_RATE = 1.0;//1.0
    private static final double EXPLORATION_DECAY = 0.995;//0.995
    private static final double MIN_EXPLORATION_RATE = 0.01;//0.01
    private static final int nbNeuronsLayer1 = 24;
    private static final int nbNeuronsLayer2 = 24;

    nbEpisode = 100_000;
	maxStep per epi = 100;
result (/100 000)
95% sucess
4.5% lose
0.5% fail
0% over

---------        ModèleV2        ---------
    private static final double LEARNING_RATE = 0.01;//0.01
    private static final double DISCOUNT_FACTOR = 0.99;//0.99
    private static double EXPLORATION_RATE = 1.0;//1.0
    private static final double EXPLORATION_DECAY = 0.995;//0.995
    private static final double MIN_EXPLORATION_RATE = 0.01;//0.01
    private static final int nbNeuronsLayer1 = 16;
    private static final int nbNeuronsLayer2 = 16;

    nbEpisode = 100_000;
	maxStep per epi = 100;
result (/20 000)
92.5% sucess
6% lose
1% fail
0% over

---------        ModèleV3        ---------
    private static final double LEARNING_RATE = 0.01;//0.01
    private static final double DISCOUNT_FACTOR = 0.99;//0.99
    private static double EXPLORATION_RATE = 1.0;//1.0
    private static final double EXPLORATION_DECAY = 0.995;//0.995
    private static final double MIN_EXPLORATION_RATE = 0.01;//0.01
    private static final int nbNeuronsLayer1 = 28;
    private static final int nbNeuronsLayer2 = 28;
    private static final int nbNeuronsLayer3 = 28;

    nbEpisode = 1_000_000;
	maxStep per epi = 100;
result (/100 000)
95% sucess
3.5% lose
1.3% fail
0% over

------     Version4     ------
Game finished
Parameters of the training : 
nbEpisodes: 70000
maxStepsPerEpisode: 100
negativeRewardForLose: -1.0
negativeRewardForCrashing: -10.0
parameter of the model : 
learning rate: 0.1
discount factor: 0.97
exploration rate: 0.009888364709658948
exploration decay: 0.95
min exploration rate: 0.01
nbNeuronsLayer1: 20
nbNeuronsLayer2: 20
result of the evaluation : 
nbOfGames: 20000
nbRoundMaxPerGame: 500
Player 1  (AI) won 0 times
Player 2 (Rdm) won 1 times
Game failed 19999 times
Game overtime 0 times


------     Version5     ------
Game finished

Parameters of the training : 
nbEpisodes: 50000
maxStepsPerEpisode: 100
negativeRewardForLose: -1.0
negativeRewardForCrashing: -1.0

parameter of the model : 
learning rate: 0.01
discount factor: 0.99
exploration rate: 0.00998645168764533
exploration decay: 0.995
min exploration rate: 0.01
Nunber of layers: 2
nbNeuronsLayer1: 24
nbNeuronsLayer2: 24

result of the evaluation : 
nbOfGames: 50000
nbRoundMaxPerGame: 500
Player 1  (AI) won 47970 times (96%)
Player 2 (Rdm) won 2030 times (4%)
Game failed 0 times (0%)
Game overtime 0 times

------     VersionV6     ------
Game finished

Parameters of the training : 
nbEpisodes: 40000
maxStepsPerEpisode: 100
negativeRewardForLose: -1.0
negativeRewardForCrashing: -1.0

parameter of the model : 
learning rate: 0.01
discount factor: 0.99
exploration rate: 0.00998645168764533
exploration decay: 0.995
min exploration rate: 0.01
Nunber of layers: 2
nbNeuronsLayer1: 24
nbNeuronsLayer2: 24

result of the evaluation : 
nbOfGames: 100000
nbRoundMaxPerGame: 500
Player 1  (AI) won 4 times
Player 2 (Rdm) won 4873 times
Game failed 95123 times
Game overtime 0 times

------     VersionV7     ------
Game finished

Parameters of the training : 
nbEpisodes: 45000
maxStepsPerEpisode: 100
negativeRewardForLose: -1.0
negativeRewardForCrashing: -1.0

parameter of the model : 
learning rate: 0.01
discount factor: 0.99
exploration rate: 0.00998645168764533
exploration decay: 0.995
min exploration rate: 0.01
Nunber of layers: 2
nbNeuronsLayer1: 24
nbNeuronsLayer2: 24

result of the evaluation : 
nbOfGames: 100000
nbRoundMaxPerGame: 500
Player 1  (AI) won 0 times
Player 2 (Rdm) won 0 times
Game failed 100000 times
Game overtime 0 times







------     Version Trash A     ------
Game finished
Parameters of the training : 
nbEpisodes: 10000
maxStepsPerEpisode: 100
negativeRewardForLose: -1.0
negativeRewardForCrashing: -100.0
parameter of the model : 
learning rate: 0.1
discount factor: 0.97
exploration rate: 0.009888364709658948
exploration decay: 0.95
min exploration rate: 0.01
Nunber of layers: 2
nbNeuronsLayer1: 20
nbNeuronsLayer2: 20
result of the evaluation : 
nbOfGames: 20000
nbRoundMaxPerGame: 500
Player 1  (AI) won 0 times
Player 2 (Rdm) won 0 times
Game failed 20000 times
Game overtime 0 times